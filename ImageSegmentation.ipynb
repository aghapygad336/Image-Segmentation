{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aghapygad336/Image-Segmentation/blob/master/ImageSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GIJrbTBgif0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "from urllib.request import urlretrieve\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qn3OPBQi5c5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if not os.path.isfile('BSR_bsds500.tgz'):\n",
        "    urlretrieve('http://www.eecs.berkeley.edu/Research/Projects/CS/vision/grouping/BSR/BSR_bsds500.tgz','BSR_bsds500.tgz')\n",
        "if not os.path.isfile('content/BSR_bsds500.tgz'):\n",
        "    !apt-get install p7zip-full\n",
        "    !p7zip -d BSR_bsds500.tgz\n",
        "    !tar -xvf BSR_bsds500.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqbvwxBWiUKR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import cv2\n",
        "\n",
        "imagesFile_path = \"BSR/BSDS500/data/images/train/\"\n",
        "imagesFile = [f for f in listdir(imagesFile_path) if isfile(join(imagesFile_path, f)) and f.endswith(\".jpg\")]\n",
        "sortedImgfiles=sorted(imagesFile)\n",
        "\n",
        "\n",
        "data = []\n",
        "\n",
        "for i in range(len(sortedImgfiles)):\n",
        "    testPlot=imagesFile_path+sortedImgfiles[i]\n",
        "    img = cv2.imread(testPlot, cv2.IMREAD_UNCHANGED)\n",
        "\n",
        "# get dimensions of image\n",
        "    dimensions = img.shape\n",
        "# height, width, number of channels in image\n",
        "    height = img.shape[0]\n",
        "    width = img.shape[1]\n",
        "    channels = img.shape[2]\n",
        "    numberTotalPixels=height*width\n",
        "    data.append(img)\n",
        "    mydata = np.array(data)\n",
        "\n",
        "print('Image Dimension    : ',dimensions)\n",
        "print('Image Height       : ',height)\n",
        "print('Image Width        : ',width)\n",
        "print('Number of Channels : ',channels)\n",
        "print('Number of Pixels   : ',numberTotalPixels)\n",
        "plt.imshow(mydata[94])\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyS3aIzPiFYO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import scipy.io\n",
        "groundTruth_path = \"BSR/BSDS500/data/groundTruth/train/\"\n",
        "groundTruthFile = [f for f in listdir(groundTruth_path) if isfile(join(groundTruth_path, f)) and f.endswith(\".mat\")]\n",
        "sortedGroundTruthFile=sorted(groundTruthFile)\n",
        "testPlot_=groundTruth_path+sortedGroundTruthFile[94]\n",
        "matContent=scipy.io.loadmat((testPlot_)) #var type is dictionary\n",
        "gt=matContent['groundTruth'][0][0][0][0][0] #getting the ground-thruth number\n",
        "plt.imshow(gt)\n",
        "plt.show()\n",
        "gt1=matContent['groundTruth'][0][0][0][0][1] #getting the ground-thruth number\n",
        "plt.imshow(gt1)\n",
        "plt.show()\n",
        "gt2=matContent['groundTruth'][0][1][0][0][0] #getting the ground-thruth number\n",
        "plt.imshow(gt2)\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dvXx9tHa_5Rx",
        "colab_type": "text"
      },
      "source": [
        " ***Color Quantization*** is the process of reducing number of colors in an image. One reason to do so is to reduce the memory. Sometimes, some devices may have limitation such that it can produce only limited number of colors. In those cases also, color quantization is performed. Here we use **k-means clustering for color quantization**. italicized text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S3wyNSUIKBy",
        "colab_type": "text"
      },
      "source": [
        "**`K-Means`**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScQISxLOTQDY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "from random import uniform\n",
        "from math import sqrt\n",
        "\n",
        "\n",
        "\n",
        "def point_avg(points):\n",
        "  \n",
        "    dimensions = len(points[0])\n",
        "\n",
        "    new_center = []\n",
        "\n",
        "    for dimension in xrange(dimensions):\n",
        "        dim_sum = 0  # dimension sum\n",
        "        for p in points:\n",
        "            dim_sum += p[dimension]\n",
        "\n",
        "        # average of each dimension\n",
        "        new_center.append(dim_sum / float(len(points)))\n",
        "\n",
        "    return new_center\n",
        "\n",
        "\n",
        "def update_centers(data_set, assignments):\n",
        "   \n",
        "    new_means = defaultdict(list)\n",
        "    centers = []\n",
        "    for assignment, point in zip(assignments, data_set):\n",
        "        new_means[assignment].append(point)\n",
        "        \n",
        "    for points in new_means.itervalues():\n",
        "        centers.append(point_avg(points))\n",
        "\n",
        "    return centers\n",
        "\n",
        "\n",
        "def assign_points(data_points, centers):\n",
        "  \n",
        "    assignments = []\n",
        "    for point in data_points:\n",
        "        shortest = ()  # positive infinity\n",
        "        shortest_index = 0\n",
        "        for i in xrange(len(centers)):\n",
        "            val = distance(point, centers[i])\n",
        "            if val < shortest:\n",
        "                shortest = val\n",
        "                shortest_index = i\n",
        "        assignments.append(shortest_index)\n",
        "    return assignments\n",
        "\n",
        "\n",
        "def distance(a, b):\n",
        "    print(\"def distance(dataset, k):\")\n",
        "\n",
        "    dimensions = len(a)\n",
        "    \n",
        "    _sum = 0\n",
        "    for dimension in xrange(dimensions):\n",
        "        difference_sq = (a[dimension] - b[dimension]) ** 2\n",
        "        _sum += difference_sq\n",
        "    return sqrt(_sum)\n",
        "\n",
        "\n",
        "def generate_k(data_set, k):\n",
        "    print(\"def generate_k(dataset, k):\")\n",
        "\n",
        "    centers = []\n",
        "    dimensions = len(data_set[0])\n",
        "    min_max = defaultdict(int)\n",
        "\n",
        "    for point in data_set:\n",
        "        for i in xrange(dimensions):\n",
        "            val = point[i]\n",
        "            min_key = 'min_%d' % i\n",
        "            max_key = 'max_%d' % i\n",
        "            if min_key not in min_max or val < min_max[min_key]:\n",
        "                min_max[min_key] = val\n",
        "            if max_key not in min_max or val > min_max[max_key]:\n",
        "                min_max[max_key] = val\n",
        "\n",
        "    for _k in xrange(k):\n",
        "        rand_point = []\n",
        "        for i in xrange(dimensions):\n",
        "            min_val = min_max['min_%d' % i]\n",
        "            max_val = min_max['max_%d' % i]\n",
        "            \n",
        "            rand_point.append(uniform(min_val, max_val))\n",
        "\n",
        "        centers.append(rand_point)\n",
        "\n",
        "    return centers\n",
        "\n",
        "\n",
        "def k_means(dataset, k):\n",
        "    print(\"def k_means(dataset, k):\")\n",
        "    k_points = generate_k(dataset, k)\n",
        "    assignments = assign_points(dataset, k_points)\n",
        "    old_assignments = None\n",
        "    while assignments != old_assignments:\n",
        "        new_centers = update_centers(dataset, assignments)\n",
        "        old_assignments = assignments\n",
        "        assignments = assign_points(dataset, new_centers)\n",
        "    return zip(assignments, dataset)\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "img = cv2.imread(    testPlot=imagesFile_path+sortedImgfiles[94])\n",
        "Z = img.reshape((-1,3))\n",
        "\n",
        "# convert to np.float32\n",
        "Z = np.float32(Z)\n",
        "print(\"go to KMEANS\")\n",
        "print (k_means(Z, 5))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}